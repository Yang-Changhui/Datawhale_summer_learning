# Datawhale暑期夏令营CV-学习笔记二

### CNN模型进阶技巧

卷积神经网络（Convolutional Neural Network，CNN）是一种深度学习模型，广泛用于图像识别、计算机视觉和模式识别任务中。CNN 在处理具有网格结构数据（如图像）时表现出色，它能够自动学习和提取图像中的特征，并在分类、定位和分割等任务中取得优秀的性能。

#### 1.对数据进行裁剪处理

对训练集样本图片和测试集样本图片统一进行自适应裁剪，具体算法思想是，由于训练集中的大脑外壳与图片的边界存在一段真空区域，这部分区域其实是无效区域，如果再进行后续的随机旋转翻转会进一步缩小ROI 的区域，也就是实际有效样本的区域，基于以上情况，本步骤的处理是尽可能针对不同尺度的大脑进行自适应裁剪边界，使得处理后的图片能尽可能贴合大脑外壳，从而增大其ROI的区域。
具体步骤如下：
1）通过遍历像素值获取各个位置的像素点
2）将设置既定像素阈值筛选出阈值之上的像素值的索引坐标
3）根据这些索引坐标进行二次筛选，选出坐标值中横纵坐标位置最大最小值，以这些坐标值来界定大脑极限边界位置；
4）对于获取的最大最小的横纵坐标值加入自适应边界系数，该系数加入的评判条件是对于最大的坐标值进行自适应扩增，对于坐标值进行自适应缩减，然后扩增或缩减后的尺度需要在原来未裁剪前的尺度范围内，否则自适应系数为0。
5）由于神经网络对样本的都会进行resize操作，因此，对于裁剪完成后的样本其尺度都不一样的情况，本步骤算法以该样本的长边为基准对短边方向进行填充扩增，确保每张图片都是以正方形的形式，这样的好处是在进行神经网络数据增强部分时候，可以一直保持着原有的长宽比，不会引发形变。

#### 2.数据增强

对于数据增强策略上的选择，通过观察可以发现，测试集中的样本具有5种变化特性，一是随机中心旋转，二是随机亮度变化，有些样本很暗，有些样本很白；三是尺度不一样，有些样本很大，有些样本比较小；因此，为增强模型泛化能力，本步骤中将在测试集和验证集统一加入如下策略：
1）随机中心旋转从-180度到180度；并以边界填充的方式进行缩放尺度；
2）随机仿射变换
3）色泽扰动，亮度随机变换幅度为0到0.5；对比度是从0到0.5；饱和度是从0到0.5，在这三种条件中进行随机变换

#### 3.标签平滑

对于常规的独热标签，为了防止出现局部最优的现象，本步骤中对样本生成的独热编码进行平滑，增大分类的泛化能力，具体步骤如下：
1）获取标签个数
2）根据标签个数和类别个数生成平滑单位矩阵，里面的值以既定平滑系数/（类别数-1）
3）标签数值平滑，即对数值为1的位置项该值减去平滑系数，其余项加上平滑系数的倒数，生成符合原标签数值分布的标签系数矩阵
4）然后对原标签矩阵进行对数交叉熵映射，然后对映射后的结果乘以平滑后的标签系数矩阵生成最终的标签矩阵。

#### 4.模型选择

可以使用2D-ResNet或者3D-ResNet等深度模型。

PyTorchImageModels,简称timm,是一个巨大的PyTorch代码集合，旨在将各种 SOTA 模型整合在一起公并具有复现 ImageNet 训练结果的能力。其中的模型也可以都进行尝试。

![image-20230726202645129](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230726202645129.png)

#### 5.损失函数

Cross Entropy Loss 或者Focal Loss,后者考虑了类别均衡。

#### 6.评价指标

由于线上有提交限制，所以可以建立本地和线上分数的对应关系，而且相同的accuarcy可能对应不同的F1-score，可以将accuarcy改成F1-score.可以根据F1-score保留最优模型，防止过拟合。

#### 参考链接：

https://github.com/genhao3/PET/

https://blog.csdn.net/qq_40150072/article/details/108698231

https://www.bilibili.com/video/BV18h4y1V7as/?spm_id_from=333.1007.top_right_bar_window_history.content.click

